Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
embedding (Embedding)        (None, 32, 200)           25200     
_________________________________________________________________
lstm (LSTM)                  (None, 32, 512)           1460224   
_________________________________________________________________
lstm_1 (LSTM)                (None, 32, 512)           2099200   
_________________________________________________________________
lstm_2 (LSTM)                (None, 512)               2099200   
_________________________________________________________________
dense (Dense)                (None, 1024)              525312    
_________________________________________________________________
activation (Activation)      (None, 1024)              0         
_________________________________________________________________
dense_1 (Dense)              (None, 126)               129150    
_________________________________________________________________
activation_1 (Activation)    (None, 126)               0         
=================================================================
Total params: 6,338,286
Trainable params: 6,338,286
Non-trainable params: 0
_________________________________________________________________
unique x: 126
unique y: 126
2022-05-10 15:39:05.157897: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)
Epoch 1/250
128/128 [==============================] - 184s 1s/step - loss: 4.4925 - val_loss: 4.3735

Epoch 00001: val_loss improved from inf to 4.37348, saving model to best_model-lstm.h5
Epoch 2/250
128/128 [==============================] - 184s 1s/step - loss: 4.2820 - val_loss: 4.2211

Epoch 00002: val_loss improved from 4.37348 to 4.22112, saving model to best_model-lstm.h5
Epoch 3/250
128/128 [==============================] - 195s 2s/step - loss: 4.1571 - val_loss: 4.1398

Epoch 00003: val_loss improved from 4.22112 to 4.13984, saving model to best_model-lstm.h5
Epoch 4/250
128/128 [==============================] - 185s 1s/step - loss: 4.0731 - val_loss: 4.0940

Epoch 00004: val_loss improved from 4.13984 to 4.09400, saving model to best_model-lstm.h5
Epoch 5/250
128/128 [==============================] - 191s 1s/step - loss: 3.9986 - val_loss: 4.0461

Epoch 00005: val_loss improved from 4.09400 to 4.04609, saving model to best_model-lstm.h5
Epoch 6/250
128/128 [==============================] - 187s 1s/step - loss: 3.9170 - val_loss: 4.0008

Epoch 00006: val_loss improved from 4.04609 to 4.00077, saving model to best_model-lstm.h5
Epoch 7/250
128/128 [==============================] - 192s 2s/step - loss: 3.8245 - val_loss: 3.9871

Epoch 00007: val_loss improved from 4.00077 to 3.98711, saving model to best_model-lstm.h5
Epoch 8/250
128/128 [==============================] - 177s 1s/step - loss: 3.6846 - val_loss: 3.9259

Epoch 00008: val_loss improved from 3.98711 to 3.92588, saving model to best_model-lstm.h5
Epoch 9/250
128/128 [==============================] - 174s 1s/step - loss: 3.5035 - val_loss: 3.8819

Epoch 00009: val_loss improved from 3.92588 to 3.88189, saving model to best_model-lstm.h5
Epoch 10/250
128/128 [==============================] - 176s 1s/step - loss: 3.2449 - val_loss: 3.8031

Epoch 00010: val_loss improved from 3.88189 to 3.80308, saving model to best_model-lstm.h5
Epoch 11/250
128/128 [==============================] - 185s 1s/step - loss: 2.9434 - val_loss: 3.8874

Epoch 00011: val_loss did not improve from 3.80308
Epoch 12/250
128/128 [==============================] - 191s 1s/step - loss: 2.5960 - val_loss: 3.9247

Epoch 00012: val_loss did not improve from 3.80308
Epoch 13/250
128/128 [==============================] - 185s 1s/step - loss: 2.1653 - val_loss: 4.1751

Epoch 00013: val_loss did not improve from 3.80308
Epoch 14/250
128/128 [==============================] - 199s 2s/step - loss: 1.6591 - val_loss: 4.4877

Epoch 00014: val_loss did not improve from 3.80308
Epoch 15/250
128/128 [==============================] - 196s 2s/step - loss: 1.1023 - val_loss: 4.9940

Epoch 00015: val_loss did not improve from 3.80308
Epoch 16/250
 61/128 [=============>................] - ETA: 1:34 - loss: 0.5781